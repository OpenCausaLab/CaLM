metric_overview_dict = [
{'Index': 1, "Metric":"Accuracy", "Class": "Metrics for Model", 'Level': 'None', 'description': "Accuracy is one of the most widely used evaluation metrics for AI systems or models. Essentially, the utility of AI systems or models hinges upon their ability to deliver precise results. In this paper, we will adopt accuracy as a standard metric for each causal scenario. This includes exact-match accuracy and the ROUGE-L score<sup>[1]</sup>. All the accuracy scores are computed by averaging over all the tested instances.", 'imageUrl': "",
"reference":"<h2>References</h2>[1] Lin, C.-Y. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pp. 74–81, 2004."},
{'Index': 2, "Metric":"Robustness", "Class": "Metrics for Model", 'Level': 'None', 'description': "Robustness is evaluated through the adversarial prompt, where responses are recorded before and after introducing disturbances, as shown in the following figure. If the answers differ, it is considered a change. The change rate is calculated as the number of changes divided by the dataset size, and the Robustness value is then expressed as 1 minus the change rate for unchanged responses, i.e., $$\\text{Robustness} = 1 - \\frac{\\text{Number of Changes}}{\\left|D\\right|}.$$ To illustrate an intuitive impression,  let us consider a specific example of how to calculate the robustness value using the given definition. Suppose we have a dataset of 100 instances, and out of these 100 prompts, 20 responses changed after introducing the disturbance. The change rate is calculated as $\\text{Change Rate} = \\frac{20}{100} = 0.2$ and the  robustness value equals $1 - 0.2 = 0.8$. Therefore, in this example, the robustness of the model is 0.8 or 80\%, indicating that 80\% of the responses remained unchanged despite the adversarial prompts. ", 'imageUrl': "../figures/metric_examples/metric_robustness.png",
"reference":""},
{'Index': 3, "Metric":"Model Volatility", "Class": "Metrics for Model", 'Level': 'None', 'description': "Model volatility is calculated as the standard deviation of the model's performance (i.e., accuracy value) across various prompting ways, namely:$$\\text{Volatility}_{i} = \\sqrt{\\frac{\\sum_{j=1}^{N}(P_{ij} - \\bar{P_{i}})^2}{N}},$$where $P_{ij}$ denotes performance of the $i$-th model under the $j$-th prompt, $\\bar{P_{i}}$ is the mean performance of the $i$-th model across all prompting ways. A higher volatility value indicates more variability in the model's performance across different prompting ways, reflecting less stability.", 'imageUrl': "",
"reference":""},
{'Index': 1, "Metric":"Understandability", "Class": "Metrics for Scenario", 'Level': 'None', 'description': "We focus on the median and third quarter of the distribution of all the model-prompt combinations in the causal task/causal scenario and compare them with a random guess. If the third quartile or the median performance of the task/scenario does not achieve a random guess, we define it as an indication that some of the models cannot understand the causal scenario or causal task even with the help of different prompts. The different degree of understanding is defined in the following table. We refer to the ''close-ended'' questions as the one that requires models to select the correct answer from a few choices instead of answering in their own words. In addition to the conditions defined in the table, we have manually defined the understandability of some open-ended questions with a random guess probability of 0\%. These open-ended scenarios are PN, PS, and CEG. Specifically, for CEG, given that most models have a better capability in processing natural language tasks, we classify its understandability as <i>easy</i>. For PN and PS, since the causal tasks in the Mathematical mode are more challenging to comprehend, with both the medians and the third quartiles less than 2\%, we classify their understandability as <i>very hard</i>.<br><br><table border=\"1\" style=\"width: 100%; text-align: center;\"><thead>    <tr>        <th>Conditions (close-ended)</th>        <th>Degree of understandability</th>    </tr></thead><tbody>    <tr>        <td>third quartile &lt; random guess</td>        <td>very hard</td>    </tr>    <tr>        <td>third quartile ≥ random guess, median &lt; random guess</td>        <td>hard</td>    </tr>    <tr>        <td>median ≥ random guess</td>        <td>easy</td>    </tr></tbody></table><caption style=\"text-align=\"left\"\"><strong>Table: Degree of understandability.</strong> The degree is used to evaluate the understandability of the causal task/causal scenario. The third quartile and median are computed from the distribution of all model-prompt pairs in a causal task/causal scenario.</caption>", 'imageUrl': "",
"reference":""},
{'Index': 1, "Metric":"Open-Limited Gap", "Class": "Metrics for Scenario", 'Level': 'None', 'description': "We evaluate the gap between open-access and limited-access models using the open-limited ratio. This ratio is calculated by comparing the performance of open-access to limited-access models among the top 5 models in terms of average prompt accuracy within the causal scenario. Typically, the limited-access models tend to outperform their open-access counterparts. The degree of the gap between open-access and limited-access models is detailed in the table. <br><br><table border=\"1\" style=\"width: 100%; text-align: center;\"><thead>    <tr>        <th>Conditions</th>        <th>Degree of open-limited gap</th>    </tr></thead><tbody>    <tr>        <td>open:limited = 0:5</td>        <td>large</td>    </tr>    <tr>        <td>open:limited = 1:4</td>        <td>moderate</td>    </tr>    <tr>        <td>open:limited &gt; 1:4</td>        <td>small</td>    </tr></tbody></table><caption style=\"text-align=\"left\"\"><strong>Table: Degree of Open-Limited Gap.</strong> The open:limited stands for the open-limited ratio computed from the top 5 models regarding (prompt) average accuracy in the causal scenario.</div>", 'imageUrl': "",
"reference":""},
{'Index': 1, "Metric":"Solvability", "Class": "Metrics for Scenario", 'Level': 'None', 'description': "The solvability focuses on the top performance of the models and the model-prompt combinations in the causal task/causal scenario; it is defined by whether the top performances of the task/causal scenario achieve the settled threshold. The solvability degree expresses the difficulty of the causal task/causal scenario. It is defined in the table.<br><br><table border=\"1\" style=\"width: 100%; text-align: center;\"><thead>    <tr>        <th>Conditions</th>        <th>Degree of solvability</th>    </tr></thead><tbody>    <tr>        <td>max value &lt; random guess</td>        <td>unsolvable (4)</td>    </tr>    <tr>        <td>random guess &le; max value &lt; 80%</td>        <td>challenging (3)</td>    </tr>    <tr>        <td>max value &ge; 80% and max average value &lt; 70%</td>        <td>potentially solvable (2)</td>    </tr>    <tr>        <td>max value &ge; 80% and max average value &ge; 70% and 3rd max average value &lt; 70%</td>        <td>solvable (1)</td>    </tr>    <tr>        <td>max value &ge; 80% and 3rd max average value &ge; 70%</td>        <td>well-solved (0)</td>    </tr></tbody></table><caption style=\"text-align=\"left\"\"><strong>Table: Degree of solvability.</strong> The degree is used to evaluate the difficulty of the causal task/causal scenario. The max value represents the max accuracy of all the model-prompt pairs in the causal task/causal scenario. The max average value represents the max average accuracy of models in the causal task/causal scenario. The 3rd max average value is the 3rd max average accuracy of models in the causal task/causal scenario. The number beside the degree of solvability is used to compute the variance of solvability in related analyses.</div>", 'imageUrl': "",
"reference":""},
{'Index': 2, "Metric":"Prompt Volatility", "Class": "Metrics for Prompt", 'Level': 'None', 'description': "Prompt volatility is determined by calculating the standard deviation of the performance values (i.e., accuracy) across various models using a specific prompting method, that is, $$\\text{Volatility}_{j} = \\sqrt{\\frac{\\sum_{i=1}^{M}(G_{ij} - \\bar{G_{j}})^2}{M}},$$where $G_{ij} = P_{ij}-P_{iB}$. $P_{ij}$ denotes performance of the $i$-th model under the $j$-th prompt, ${P_{iB}}$ is the $i$-th model's performance using basic prompt. Therefore, $G_{ij}$ denotes the gain in the $i$-th model's performance on the $j$-th prompt compared to the basic prompt. This metric helps us to compare the performance between different prompting strategies with the basic prompt. A higher volatility value indicates a larger influence of the prompt on models compared to the basic prompt.", 'imageUrl': "",
"reference":""},
]