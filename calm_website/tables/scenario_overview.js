multi_scenario_performance = [{'Rank': 0, 'Scenario': 'Abstract Reasoning', 'Level': 'Causal Discovery', 'Random Guess': 50.0, 'Average': 52.9, 'Std': 9.3, 'Median': 53.1, 'Third Quartile': 62.6, 'Basic': 55.1, 'Doubt': 50.7, 'Ignore': 49.8, '0-shot IcL': 56.6, '1-shot IcL': 56.6, '3-shot IcL': 55.7, '0-shot CoT': 52.2, 'Manual CoT': 42.9, 'EF': 56.1, 'EN': 54.9, 'CN': 51.2, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 92.6, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 88.3},
{'Rank': 1, 'Scenario': 'Correlation', 'Level': 'Association', 'Random Guess': 50.0, 'Average': 46.0, 'Std': 7.1, 'Median': 49.9, 'Third Quartile': 51.5, 'Basic': 45.2, 'Doubt': 44.7, 'Ignore': 43.7, '0-shot IcL': 44.9, '1-shot IcL': 50.9, '3-shot IcL': 51.3, '0-shot CoT': 43.6, 'Manual CoT': 43.7, 'EF': 46.1, 'EN': 47.4, 'CN': 44.3, 'Top 1 Combination': '(Claude2, EF)', 'Top 1 Combination Value': 68.0, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 59.1},
{'Rank': 2, 'Scenario': 'Explaining Away Effect', 'Level': 'Association', 'Random Guess': 50.0, 'Average': 45.5, 'Std': 9.3, 'Median': 48.8, 'Third Quartile': 50.7, 'Basic': 45.7, 'Doubt': 44.2, 'Ignore': 43.9, '0-shot IcL': 45.0, '1-shot IcL': 49.6, '3-shot IcL': 51.3, '0-shot CoT': 43.7, 'Manual CoT': 38.7, 'EF': 47.5, 'EN': 48.2, 'CN': 42.8, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 90.5, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 67.9},
{'Rank': 3, 'Scenario': 'Frontdoor Adjustment Set', 'Level': 'Intervention', 'Random Guess': 33.3, 'Average': 28.7, 'Std': 9.6, 'Median': 29.0, 'Third Quartile': 35.6, 'Basic': 25.2, 'Doubt': 24.5, 'Ignore': 24.0, '0-shot IcL': 33.2, '1-shot IcL': 35.9, '3-shot IcL': 38.5, '0-shot CoT': 24.5, 'Manual CoT': 25.3, 'EF': 27.3, 'EN': 28.9, 'CN': 27.8, 'Top 1 Combination': '(GPT-4, 3-shot IcL)', 'Top 1 Combination Value': 95.2, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 77.2},
{'Rank': 4, 'Scenario': 'Instrumental Variable', 'Level': 'Intervention', 'Random Guess': 33.3, 'Average': 30.3, 'Std': 9.2, 'Median': 30.7, 'Third Quartile': 37.9, 'Basic': 24.7, 'Doubt': 23.0, 'Ignore': 23.2, '0-shot IcL': 33.1, '1-shot IcL': 36.2, '3-shot IcL': 38.0, '0-shot CoT': 28.0, 'Manual CoT': 39.9, 'EF': 26.2, 'EN': 30.9, 'CN': 28.5, 'Top 1 Combination': '(GPT-4, 3-shot IcL)', 'Top 1 Combination Value': 78.9, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 74.8},
{'Rank': 5, 'Scenario': 'Collider Bias', 'Level': 'Intervention', 'Random Guess': 50.0, 'Average': 42.0, 'Std': 10.6, 'Median': 43.0, 'Third Quartile': 50.6, 'Basic': 38.1, 'Doubt': 37.9, 'Ignore': 38.8, '0-shot IcL': 36.1, '1-shot IcL': 47.8, '3-shot IcL': 51.8, '0-shot CoT': 35.6, 'Manual CoT': 53.6, 'EF': 37.9, 'EN': 44.7, 'CN': 38.5, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 97.8, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 62.7},
{'Rank': 6, 'Scenario': 'Actual Causality', 'Level': 'Counterfactual', 'Random Guess': 50.0, 'Average': 38.1, 'Std': 10.7, 'Median': 45.0, 'Third Quartile': 51.9, 'Basic': 34.8, 'Doubt': 33.8, 'Ignore': 33.3, '0-shot IcL': 41.4, '1-shot IcL': 50.5, '3-shot IcL': 48.6, '0-shot CoT': 33.1, 'Manual CoT': 33.6, 'EF': 33.5, 'EN': 39.7, 'CN': 35.8, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 68.2, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 65.6},
{'Rank': 7, 'Scenario': 'Causal Explanation Generation', 'Level': 'Counterfactual', 'Random Guess': 0.0, 'Average': 35.7, 'Std': 5.7, 'Median': 35.0, 'Third Quartile': 40.8, 'Basic': 38.2, 'Doubt': 39.7, 'Ignore': 34.3, '0-shot IcL': 36.1, '1-shot IcL': 33.6, '3-shot IcL': 32.0, '0-shot CoT': 35.6, 'Manual CoT': 36.8, 'EF': 35.0, 'EN': 30.4, 'CN': 41.3, 'Top 1 Combination': '(Claude2, EF)', 'Top 1 Combination Value': 63.4, 'Top 1 Average Model': 'Claude2', 'Top 1 Average': 59.1},
{'Rank': 8, 'Scenario': 'Pairwise Causal Discovery', 'Level': 'Causal Discovery', 'Random Guess': 50.0, 'Average': 57.1, 'Std': 6.8, 'Median': 54.1, 'Third Quartile': 68.8, 'Basic': 56.4, 'Doubt': 52.2, 'Ignore': 52.9, '0-shot IcL': 59.9, '1-shot IcL': 63.4, '3-shot IcL': 65.4, '0-shot CoT': 53.3, 'Manual CoT': 50.7, 'EF': 59.8, 'EN': 58.6, 'CN': 55.5, 'Top 1 Combination': '(GPT-4, EF)', 'Top 1 Combination Value': 83.0, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 79.1},
{'Rank': 9, 'Scenario': 'Event Causality Identification', 'Level': 'Causal Discovery', 'Random Guess': 50.0, 'Average': 48.9, 'Std': 7.2, 'Median': 51.4, 'Third Quartile': 54.9, 'Basic': 50.5, 'Doubt': 47.2, 'Ignore': 46.8, '0-shot IcL': 50.3, '1-shot IcL': 53.6, '3-shot IcL': 52.6, '0-shot CoT': 41.9, 'Manual CoT': 47.1, 'EF': 50.3, 'EN': 51.0, 'CN': 47.1, 'Top 1 Combination': '(GPT-4, adversarial doubt)', 'Top 1 Combination Value': 67.0, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 65.6},
{'Rank': 10, 'Scenario': 'Causal Attribution', 'Level': 'Causal Discovery', 'Random Guess': 50.0, 'Average': 55.8, 'Std': 6.9, 'Median': 55.9, 'Third Quartile': 61.8, 'Basic': 57.4, 'Doubt': 53.0, 'Ignore': 54.1, '0-shot IcL': 58.1, '1-shot IcL': 58.4, '3-shot IcL': 55.7, '0-shot CoT': 53.6, 'Manual CoT': 55.9, 'EF': 55.6, 'EN': 54.9, 'CN': 56.9, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 94.8, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 91.8},
{'Rank': 11, 'Scenario': 'Average Treatment Effect', 'Level': 'Intervention', 'Random Guess': 16.7, 'Average': 19.1, 'Std': 14.5, 'Median': 9.4, 'Third Quartile': 28.6, 'Basic': 13.5, 'Doubt': 12.5, 'Ignore': 12.9, '0-shot IcL': 11.6, '1-shot IcL': 16.3, '3-shot IcL': 38.5, '0-shot CoT': 11.7, 'Manual CoT': 35.9, 'EF': '-', 'EN': 19.0, 'CN': 11.4, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 92.8, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 54.8},
{'Rank': 12, 'Scenario': 'Controlled Direct Effect', 'Level': 'Intervention', 'Random Guess': 16.7, 'Average': 17.1, 'Std': 13.4, 'Median': 9.3, 'Third Quartile': 24.7, 'Basic': 12.0, 'Doubt': 11.6, 'Ignore': 11.6, '0-shot IcL': 11.0, '1-shot IcL': 16.0, '3-shot IcL': 33.7, '0-shot CoT': 8.3, 'Manual CoT': 32.9, 'EF': '-', 'EN': 16.9, 'CN': 10.4, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 90.8, 'Top 1 Average Model': 'GPT-3.5-Turbo', 'Top 1 Average': 47.6},
{'Rank': 13, 'Scenario': 'Causal Effect Identification', 'Level': 'Intervention', 'Random Guess': 50.0, 'Average': 43.3, 'Std': 6.0, 'Median': 46.6, 'Third Quartile': 49.3, 'Basic': 42.3, 'Doubt': 42.3, 'Ignore': 41.3, '0-shot IcL': 43.2, '1-shot IcL': 48.9, '3-shot IcL': 47.7, '0-shot CoT': 40.6, 'Manual CoT': 39.4, 'EF': 43.8, 'EN': 42.3, 'CN': 44.1, 'Top 1 Combination': '(GPT-4, 3-shot IcL)', 'Top 1 Combination Value': 59.0, 'Top 1 Average Model': 'GPT-3.5-Turbo', 'Top 1 Average': 49.9},
{'Rank': 14, 'Scenario': 'Backdoor Adjustment Set', 'Level': 'Intervention', 'Random Guess': 37.5, 'Average': 33.1, 'Std': 7.4, 'Median': 34.0, 'Third Quartile': 40.0, 'Basic': 29.2, 'Doubt': 26.9, 'Ignore': 27.1, '0-shot IcL': 37.3, '1-shot IcL': 39.1, '3-shot IcL': 41.3, '0-shot CoT': 31.0, 'Manual CoT': 37.4, 'EF': 28.3, 'EN': 34.8, 'CN': 30.5, 'Top 1 Combination': '(GPT-4, 3-shot IcL)', 'Top 1 Combination Value': 75.1, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 71.6},
{'Rank': 15, 'Scenario': 'Counterfactual Reasoning', 'Level': 'Counterfactual', 'Random Guess': 37.5, 'Average': 43.8, 'Std': 6.7, 'Median': 38.8, 'Third Quartile': 54.3, 'Basic': 42.3, 'Doubt': 39.7, 'Ignore': 40.0, '0-shot IcL': 43.7, '1-shot IcL': 47.8, '3-shot IcL': 48.3, '0-shot CoT': 39.5, 'Manual CoT': 49.6, 'EF': 43.0, 'EN': 46.6, 'CN': 40.6, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 83.2, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 76.9},
{'Rank': 16, 'Scenario': 'Effect of the Treatment on the Treated', 'Level': 'Counterfactual', 'Random Guess': 16.7, 'Average': 18.2, 'Std': 14.5, 'Median': 12.5, 'Third Quartile': 25.2, 'Basic': 11.6, 'Doubt': 11.2, 'Ignore': 11.3, '0-shot IcL': 10.0, '1-shot IcL': 23.0, '3-shot IcL': 28.4, '0-shot CoT': 8.5, 'Manual CoT': 42.0, 'EF': '-', 'EN': 17.6, 'CN': 11.4, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 89.9, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 40.9},
{'Rank': 17, 'Scenario': 'Natural Direct Effect', 'Level': 'Counterfactual', 'Random Guess': 16.7, 'Average': 17.0, 'Std': 10.2, 'Median': 14.0, 'Third Quartile': 19.9, 'Basic': 13.2, 'Doubt': 12.8, 'Ignore': 12.5, '0-shot IcL': 12.1, '1-shot IcL': 21.1, '3-shot IcL': 23.1, '0-shot CoT': 9.3, 'Manual CoT': 32.3, 'EF': '-', 'EN': 15.7, 'CN': 12.9, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 80.1, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 42.6},
{'Rank': 18, 'Scenario': 'Natural Indirect Effect', 'Level': 'Counterfactual', 'Random Guess': 16.7, 'Average': 15.4, 'Std': 16.1, 'Median': 6.7, 'Third Quartile': 19.0, 'Basic': 9.4, 'Doubt': 9.7, 'Ignore': 9.4, '0-shot IcL': 8.0, '1-shot IcL': 12.8, '3-shot IcL': 38.7, '0-shot CoT': 6.8, 'Manual CoT': 28.8, 'EF': '-', 'EN': 15.3, 'CN': 7.8, 'Top 1 Combination': '(Koala (13B), 3-shot IcL)', 'Top 1 Combination Value': 73.3, 'Top 1 Average Model': 'GPT-3.5-Turbo', 'Top 1 Average': 43.0},
{'Rank': 19, 'Scenario': 'Probability of Necessity', 'Level': 'Counterfactual', 'Random Guess': 0.0, 'Average': 2.6, 'Std': 4.1, 'Median': 0.3, 'Third Quartile': 1.6, 'Basic': 0.9, 'Doubt': 1.1, 'Ignore': 1.1, '0-shot IcL': 0.7, '1-shot IcL': 1.0, '3-shot IcL': 8.1, '0-shot CoT': 0.7, 'Manual CoT': 7.0, 'EF': '-', 'EN': 2.6, 'CN': 0.5, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 50.2, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 14.5},
{'Rank': 20, 'Scenario': 'Probability of Sufficiency', 'Level': 'Counterfactual', 'Random Guess': 0.0, 'Average': 1.5, 'Std': 2.7, 'Median': 0.0, 'Third Quartile': 0.4, 'Basic': 0.7, 'Doubt': 0.9, 'Ignore': 1.0, '0-shot IcL': 0.8, '1-shot IcL': 0.3, '3-shot IcL': 0.1, '0-shot CoT': 0.7, 'Manual CoT': 7.7, 'EF': '-', 'EN': 1.5, 'CN': 0.6, 'Top 1 Combination': '(GPT-4, manual CoT)', 'Top 1 Combination Value': 46.8, 'Top 1 Average Model': 'GPT-4', 'Top 1 Average': 12.6},
]